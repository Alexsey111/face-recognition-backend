#!/bin/bash
# =============================================================================
# GPU Health Check Script
# =============================================================================
# –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å CUDA/GPU –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ Face Recognition Service
#
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ:
#   ./scripts/check_gpu.sh
#
# –ò–ª–∏ —á–µ—Ä–µ–∑ docker exec:
#   docker exec face-recognition python scripts/check_gpu.py
# =============================================================================

set -e

echo "========================================"
echo "üîç GPU/CUDA Health Check"
echo "========================================"
echo ""

# 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ nvidia-smi
echo "1Ô∏è‚É£  Checking nvidia-smi..."
if command -v nvidia-smi &> /dev/null; then
    echo "   ‚úÖ nvidia-smi found"
    nvidia-smi --query-gpu=index,name,memory.total,driver_version \
        --format=csv,noheader,nounits 2>/dev/null || echo "   ‚ÑπÔ∏è  nvidia-smi works but query failed"
else
    echo "   ‚ùå nvidia-smi not found"
fi
echo ""

# 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ CUDA driver
echo "2Ô∏è‚É£  Checking CUDA driver..."
if nvidia-smi &> /dev/null; then
    CUDA_DRIVER=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader 2>/dev/null | head -1)
    echo "   ‚úÖ CUDA Driver: $CUDA_DRIVER"
else
    echo "   ‚ùå CUDA driver not accessible"
fi
echo ""

# 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ CUDA version
echo "3Ô∏è‚É£  Checking CUDA version..."
if command -v nvcc &> /dev/null; then
    CUDA_VERSION=$(nvcc --version | grep "release" | awk '{print $5}')
    echo "   ‚úÖ CUDA Toolkit: $CUDA_VERSION"
else
    echo "   ‚ÑπÔ∏è  nvcc not installed (CUDA Toolkit)"
fi
echo ""

# 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ Python/PyTorch
echo "4Ô∏è‚É£  Checking PyTorch CUDA..."
python3 << 'PYTHON_EOF'
import sys
try:
    import torch
    print(f"   ‚úÖ PyTorch version: {torch.__version__}")
    print(f"   ‚úÖ CUDA available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"   ‚úÖ CUDA version: {torch.version.cuda}")
        print(f"   ‚úÖ GPU count: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            gpu_name = torch.cuda.get_device_name(i)
            gpu_mem = torch.cuda.get_device_properties(i).total_memory / 1024**3
            print(f"      GPU {i}: {gpu_name} ({gpu_mem:.1f} GB)")
    else:
        print("   ‚ö†Ô∏è  CUDA not available in PyTorch")
        sys.exit(1)
except Exception as e:
    print(f"   ‚ùå PyTorch CUDA check failed: {e}")
    sys.exit(1)
PYTHON_EOF

echo ""

# 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ FaceNet/PyTorch
echo "5Ô∏è‚É£  Checking FaceNet model loading..."
python3 << 'PYTHON_EOF'
import sys
import time
start = time.time()

try:
    from facenet_pytorch import Mtcnn, InceptionResnetV1
    import torch
    
    print("   ‚úÖ facenet-pytorch imported successfully")
    
    # Check device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"   üì± Device: {device}")
    
    # Load MTCNN (face detection)
    mtcnn = Mtcnn(image_size=160, margin=0).to(device)
    print("   ‚úÖ MTCNN loaded")
    
    # Load FaceNet (embedding)
    resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)
    print("   ‚úÖ InceptionResnetV1 loaded")
    
    elapsed = time.time() - start
    print(f"   ‚è±Ô∏è  Model load time: {elapsed:.2f}s")
    
    # Test inference
    import numpy as np
    dummy = torch.randn(1, 3, 160, 160).to(device)
    with torch.no_grad():
        output = resnet(dummy)
    print(f"   ‚úÖ Inference test passed (output shape: {output.shape})")
    
except Exception as e:
    print(f"   ‚ùå FaceNet loading failed: {e}")
    sys.exit(1)
PYTHON_EOF

echo ""
echo "========================================"
echo "‚úÖ GPU Health Check PASSED"
echo "========================================"
echo ""
echo "üìã Quick commands:"
echo "   docker exec face-recognition nvidia-smi"
echo "   docker exec face-recognition python scripts/check_gpu.py"
echo ""
echo "üåê Useful URLs:"
echo "   Prometheus: http://localhost:9090"
echo "   Grafana:    http://localhost:3000"
echo "   API Docs:   http://localhost:8000/docs"