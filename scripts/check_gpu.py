#!/usr/bin/env python3
"""
GPU Health Check Script –¥–ª—è Face Recognition Service.

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å CUDA/GPU –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã PyTorch.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python scripts/check_gpu.py
"""

import sys
import time


def check_nvidia_smi():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ nvidia-smi."""
    import subprocess
    
    try:
        result = subprocess.run(
            ["nvidia-smi", "--query-gpu=name,memory.total,driver_version", 
             "--format=csv,noheader,nounits"],
            capture_output=True, text=True, timeout=10
        )
        if result.returncode == 0:
            print("‚úÖ nvidia-smi –¥–æ—Å—Ç—É–ø–µ–Ω")
            for line in result.stdout.strip().split("\n"):
                name, mem, driver = line.split(", ")
                print(f"   GPU: {name}, Memory: {mem} MB, Driver: {driver}")
            return True
        else:
            print("‚ùå nvidia-smi –≤–µ—Ä–Ω—É–ª –æ—à–∏–±–∫—É")
            return False
    except FileNotFoundError:
        print("‚ùå nvidia-smi –Ω–µ –Ω–∞–π–¥–µ–Ω (NVIDIA Driver –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ nvidia-smi: {e}")
        return False


def check_cuda():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ CUDA —á–µ—Ä–µ–∑ PyTorch."""
    try:
        import torch
        print(f"‚úÖ PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}")
        
        if torch.cuda.is_available():
            print(f"‚úÖ CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.version.cuda}")
            print(f"‚úÖ GPU —É—Å—Ç—Ä–æ–π—Å—Ç–≤: {torch.cuda.device_count()}")
            
            for i in range(torch.cuda.device_count()):
                props = torch.cuda.get_device_properties(i)
                mem_gb = props.total_memory / (1024**3)
                print(f"   GPU {i}: {props.name}")
                print(f"      Memory: {mem_gb:.1f} GB")
                print(f"      Compute Capability: {props.major}.{props.minor}")
            return True
        else:
            print("‚ö†Ô∏è CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –≤ PyTorch (—Ä–∞–±–æ—Ç–∞–µ–º –Ω–∞ CPU)")
            return False
    except ImportError as e:
        print(f"‚ùå PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {e}")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ CUDA: {e}")
        return False


def check_facenet_models():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π FaceNet."""
    try:
        import torch
        from facenet_pytorch import Mtcnn, InceptionResnetV1
        
        print("‚úÖ facenet-pytorch –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
        
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"üì± –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
        
        start = time.time()
        
        # MTCNN –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü–∞
        mtcnn = Mtcnn(image_size=160, margin=0).to(device)
        print("‚úÖ MTCNN –∑–∞–≥—Ä—É–∂–µ–Ω")
        
        # FaceNet –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)
        print("‚úÖ InceptionResnetV1 –∑–∞–≥—Ä—É–∂–µ–Ω")
        
        elapsed = time.time() - start
        print(f"‚è±Ô∏è –í—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏: {elapsed:.2f}s")
        
        # –¢–µ—Å—Ç–æ–≤—ã–π inference
        dummy = torch.randn(1, 3, 160, 160).to(device)
        with torch.no_grad():
            embedding = resnet(dummy)
        print(f"‚úÖ –¢–µ—Å—Ç–æ–≤—ã–π inference: shape={embedding.shape}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}")
        return False


def check_liveness_model():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ MiniFASNetV2 –¥–ª—è liveness detection."""
    try:
        import torch
        from app.services.anti_spoofing_service import AntiSpoofingService
        
        print("‚úÖ AntiSpoofingService –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")
        
        service = AntiSpoofingService()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"üì± Anti-Spoofing device: {device}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –º–æ–¥–µ–ª–∏
        model_status = service.get_model_status()
        print(f"üìä Model status: {model_status}")
        
        return True
        
    except Exception as e:
        print(f"‚ö†Ô∏è Anti-Spoofing check skipped: {e}")
        return True  # –ù–µ –∫—Ä–∏—Ç–∏—á–Ω–æ


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏."""
    print("=" * 50)
    print("üîç GPU/CUDA Health Check")
    print("=" * 50)
    print()
    
    results = []
    
    # 1. nvidia-smi
    print("1Ô∏è‚É£  NVIDIA Driver (nvidia-smi)")
    results.append(("nvidia-smi", check_nvidia_smi()))
    print()
    
    # 2. CUDA
    print("2Ô∏è‚É£  CUDA/PyTorch")
    results.append(("CUDA", check_cuda()))
    print()
    
    # 3. FaceNet models
    print("3Ô∏è‚É£  FaceNet Models (MTCNN + InceptionResnetV1)")
    results.append(("FaceNet", check_facenet_models()))
    print()
    
    # 4. Liveness model
    print("4Ô∏è‚É£  Liveness Detection (MiniFASNetV2)")
    results.append(("Liveness", check_liveness_model()))
    print()
    
    # –ò—Ç–æ–≥
    print("=" * 50)
    print("üìã –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏:")
    print("=" * 50)
    
    all_passed = True
    for name, passed in results:
        status = "‚úÖ" if passed else "‚ùå"
        print(f"   {status} {name}")
        if not passed:
            all_passed = False
    
    print()
    if all_passed:
        print("‚úÖ –í—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã!")
        print()
        print("üåê –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏:")
        print("   Prometheus: http://localhost:9090")
        print("   Grafana:    http://localhost:3000")
        print("   API Docs:   http://localhost:8000/docs")
        return 0
    else:
        print("‚ö†Ô∏è –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–µ –ø—Ä–æ–π–¥–µ–Ω—ã")
        print("   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Docker —Å NVIDIA runtime")
        return 1


if __name__ == "__main__":
    sys.exit(main())