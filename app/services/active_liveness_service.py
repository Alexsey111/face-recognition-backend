"""
Active Liveness Detection Service.

Supports:
- Blink detection (–º–æ—Ä–≥–∞–Ω–∏–µ)
- Head movement detection (–ø–æ–≤–æ—Ä–æ—Ç—ã –≥–æ–ª–æ–≤—ã)
- Smile detection (—É–ª—ã–±–∫–∞)
- Combined active + passive liveness verification
"""

import asyncio
import uuid
from datetime import datetime, timedelta, timezone
from typing import Any, Dict, List, Optional, Tuple

import cv2
import numpy as np

from ..models.active_liveness import (
    ActiveLivenessChallengeResponse,
    ActiveLivenessVerifyResponse,
    BlinkDetectionResult,
    ChallengeInstruction,
    ChallengeSession,
    ChallengeType,
    CombinedLivenessScore,
    HeadMovementResult,
    OcclusionDetectionResult,
    SmileDetectionResult,
)
from ..services.face_occlusion_detector import get_occlusion_detector
from ..utils.exceptions import ProcessingError, ValidationError
from ..utils.eye_blink_detector import BlinkDetector, detect_blinks_in_sequence
from ..utils.face_alignment_utils import detect_face_landmarks
from ..utils.logger import get_logger
from ..utils.mouth_detector import (
    calculate_mouth_aspect_ratio,
    detect_open_mouth_in_sequence,
    detect_smile_in_sequence,
)
from ..utils.video_processing import calculate_video_quality, extract_frames_from_video

logger = get_logger(__name__)


class ActiveLivenessService:
    """
    –°–µ—Ä–≤–∏—Å Active Liveness Detection.

    Features:
    - Challenge-based liveness (blink, smile, head turn)
    - Video/image sequence processing
    - Combined active + passive verification
    - Challenge session management
    """

    def __init__(self):
        # –•—Ä–∞–Ω–∏–ª–∏—â–µ –∞–∫—Ç–∏–≤–Ω—ã—Ö —á–µ–ª–ª–µ–Ω–¥–∂–µ–π (in-memory, –¥–ª—è production –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Redis)
        self._active_challenges: Dict[str, ChallengeSession] = {}

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        self.default_timeout_seconds = 15
        self.max_video_duration_seconds = 30
        self.min_frames_required = 20

        # –ü–æ—Ä–æ–≥–∏ –¥–µ—Ç–µ–∫—Ü–∏–∏
        self.blink_ear_threshold = 0.21
        self.head_movement_min_angle = 15.0
        self.smile_intensity_threshold = 0.6

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            "challenges_created": 0,
            "challenges_completed": 0,
            "challenges_failed": 0,
        }

    # ========================================================================
    # Challenge Creation
    # ========================================================================

    async def create_challenge(
        self,
        challenge_type: ChallengeType = "random",
        timeout_seconds: int = 10,
        difficulty: str = "medium",
    ) -> ActiveLivenessChallengeResponse:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ Active Liveness —á–µ–ª–ª–µ–Ω–¥–∂–∞.

        Args:
            challenge_type: –¢–∏–ø —á–µ–ª–ª–µ–Ω–¥–∂–∞
            timeout_seconds: –í—Ä–µ–º—è –Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
            difficulty: –°–ª–æ–∂–Ω–æ—Å—Ç—å (easy/medium/hard)

        Returns:
            ActiveLivenessChallengeResponse —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏
        """
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º random challenge –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω–æ
        if challenge_type == "random":
            import random

            challenge_type = random.choice(
                [
                    "blink",
                    "smile",
                    "turn_head_left",
                    "turn_head_right",
                ]
            )

        # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID
        challenge_id = str(uuid.uuid4())

        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é
        instruction = self._get_challenge_instruction(challenge_type, difficulty)

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —á–µ–ª–ª–µ–Ω–¥–∂–∞
        parameters = self._get_challenge_parameters(challenge_type, difficulty)

        # –°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é
        now = datetime.now(timezone.utc)
        expires_at = now + timedelta(seconds=timeout_seconds)

        session = ChallengeSession(
            challenge_id=challenge_id,
            challenge_type=challenge_type,
            created_at=now,
            expires_at=expires_at,
            parameters=parameters,
            status="pending",
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        self._active_challenges[challenge_id] = session
        self.stats["challenges_created"] += 1

        logger.info(f"Created challenge: {challenge_id}, type={challenge_type}")

        return ActiveLivenessChallengeResponse(
            success=True,
            challenge_id=challenge_id,
            challenge_type=challenge_type,
            instruction=instruction,
            expires_at=expires_at,
            expected_duration_seconds=instruction.duration_seconds,
            min_frames_required=parameters.get("min_frames", 30),
            recommended_fps=30,
        )

    def _get_challenge_instruction(
        self,
        challenge_type: ChallengeType,
        difficulty: str,
    ) -> ChallengeInstruction:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è —á–µ–ª–ª–µ–Ω–¥–∂–∞."""

        instructions = {
            "blink": ChallengeInstruction(
                text="–ú–æ—Ä–≥–Ω–∏—Ç–µ 2 —Ä–∞–∑–∞" if difficulty != "hard" else "–ú–æ—Ä–≥–Ω–∏—Ç–µ 3 —Ä–∞–∑–∞",
                icon="üëÅÔ∏è",
                duration_seconds=5 if difficulty == "easy" else 3,
            ),
            "smile": ChallengeInstruction(
                text="–£–ª—ã–±–Ω–∏—Ç–µ—Å—å",
                icon="üòä",
                duration_seconds=3,
            ),
            "turn_head_left": ChallengeInstruction(
                text="–ü–æ–≤–µ—Ä–Ω–∏—Ç–µ –≥–æ–ª–æ–≤—É –≤–ª–µ–≤–æ",
                icon="‚¨ÖÔ∏è",
                duration_seconds=3,
            ),
            "turn_head_right": ChallengeInstruction(
                text="–ü–æ–≤–µ—Ä–Ω–∏—Ç–µ –≥–æ–ª–æ–≤—É –≤–ø—Ä–∞–≤–æ",
                icon="‚û°Ô∏è",
                duration_seconds=3,
            ),
            "turn_head_up": ChallengeInstruction(
                text="–ù–∞–∫–ª–æ–Ω–∏—Ç–µ –≥–æ–ª–æ–≤—É –≤–≤–µ—Ä—Ö",
                icon="‚¨ÜÔ∏è",
                duration_seconds=3,
            ),
            "turn_head_down": ChallengeInstruction(
                text="–ù–∞–∫–ª–æ–Ω–∏—Ç–µ –≥–æ–ª–æ–≤—É –≤–Ω–∏–∑",
                icon="‚¨áÔ∏è",
                duration_seconds=3,
            ),
            "open_mouth": ChallengeInstruction(
                text="–û—Ç–∫—Ä–æ–π—Ç–µ —Ä–æ—Ç",
                icon="üòÆ",
                duration_seconds=2,
            ),
        }

        return instructions.get(challenge_type, instructions["blink"])

    def _get_challenge_parameters(
        self,
        challenge_type: ChallengeType,
        difficulty: str,
    ) -> Dict[str, Any]:
        """–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —á–µ–ª–ª–µ–Ω–¥–∂–∞."""

        difficulty_multipliers = {
            "easy": 0.8,
            "medium": 1.0,
            "hard": 1.3,
        }

        multiplier = difficulty_multipliers.get(difficulty, 1.0)

        base_params = {
            "blink": {
                "min_blinks": 2 if difficulty != "hard" else 3,
                "ear_threshold": self.blink_ear_threshold,
                "min_frames": 20,
            },
            "smile": {
                "intensity_threshold": self.smile_intensity_threshold * multiplier,
                "min_duration_frames": int(15 * multiplier),
            },
            "turn_head_left": {
                "min_angle": self.head_movement_min_angle * multiplier,
                "direction": "left",
            },
            "turn_head_right": {
                "min_angle": self.head_movement_min_angle * multiplier,
                "direction": "right",
            },
            "turn_head_up": {
                "min_angle": self.head_movement_min_angle * multiplier,
                "direction": "up",
            },
            "turn_head_down": {
                "min_angle": self.head_movement_min_angle * multiplier,
                "direction": "down",
            },
            "open_mouth": {
                "mouth_aspect_ratio_threshold": 0.5 * multiplier,
                "min_duration_frames": 10,
            },
        }

        return base_params.get(challenge_type, base_params["blink"])

    # ========================================================================
    # Challenge Verification
    # ========================================================================

    async def verify_challenge(
        self,
        challenge_id: str,
        video_data: Optional[bytes] = None,
        image_sequence: Optional[List[bytes]] = None,
        metadata: Optional[Dict[str, Any]] = None,
    ) -> ActiveLivenessVerifyResponse:
        """
        –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —á–µ–ª–ª–µ–Ω–¥–∂–∞.

        Args:
            challenge_id: ID —á–µ–ª–ª–µ–Ω–¥–∂–∞
            video_data: –í–∏–¥–µ–æ (–µ—Å–ª–∏ –µ—Å—Ç—å)
            image_sequence: –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            metadata: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

        Returns:
            ActiveLivenessVerifyResponse —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        """
        start_time = asyncio.get_event_loop().time()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —á–µ–ª–ª–µ–Ω–¥–∂–∞
        if challenge_id not in self._active_challenges:
            raise ValidationError(f"Challenge {challenge_id} not found or expired")

        session = self._active_challenges[challenge_id]

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è
        if datetime.now(timezone.utc) > session.expires_at:
            session.status = "expired"
            raise ValidationError(f"Challenge {challenge_id} has expired")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã
        if not video_data and not image_sequence:
            raise ValidationError(
                "Either video_data or image_sequence must be provided"
            )

        try:
            # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–¥—Ä—ã
            if video_data:
                frames = await asyncio.to_thread(
                    extract_frames_from_video,
                    video_data,
                    max_frames=300,
                    target_fps=30,
                )
            else:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º image_sequence –≤ frames
                frames = await self._load_image_sequence(image_sequence)

            if len(frames) < self.min_frames_required:
                raise ProcessingError(
                    f"Insufficient frames: got {len(frames)}, need {self.min_frames_required}"
                )

            # 2. –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –≤–∏–¥–µ–æ
            video_quality = await asyncio.to_thread(calculate_video_quality, frames)

            if video_quality["quality_score"] < 0.3:
                raise ProcessingError(
                    f"Video quality too low: {video_quality['quality_score']:.2f}"
                )

            # 3. –î–µ—Ç–µ–∫—Ü–∏—è landmarks –¥–ª—è –≤—Å–µ—Ö –∫–∞–¥—Ä–æ–≤
            landmarks_sequence = await self._extract_landmarks_sequence(frames)

            if len(landmarks_sequence) < self.min_frames_required:
                raise ProcessingError(
                    f"Face not detected in enough frames: {len(landmarks_sequence)}/{len(frames)}"
                )

            # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫–∫–ª—é–∑–∏–π
            occlusion_result = await self._check_occlusions(
                frames[0], landmarks_sequence[0]
            )

            # 5. –í—ã–ø–æ–ª–Ω—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—É—é –¥–ª—è —á–µ–ª–ª–µ–Ω–¥–∂–∞ –¥–µ—Ç–µ–∫—Ü–∏—é
            challenge_result = await self._verify_specific_challenge(
                session.challenge_type,
                session.parameters,
                frames,
                landmarks_sequence,
            )

            # 6. –ü–∞—Å—Å–∏–≤–Ω–∞—è liveness –ø—Ä–æ–≤–µ—Ä–∫–∞ (–¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏)
            passive_result = await self._run_passive_liveness(frames[0])

            # 7. –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
            combined_score = self._calculate_combined_score(
                challenge_result,
                passive_result,
                occlusion_result,
            )

            # 8. –§–∏–Ω–∞–ª—å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ
            liveness_detected = combined_score["overall_score"] > 0.7
            challenge_completed = challenge_result["success"]

            success = liveness_detected and challenge_completed

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å —á–µ–ª–ª–µ–Ω–¥–∂–∞
            session.status = "completed" if success else "failed"
            session.result = {
                "liveness_detected": liveness_detected,
                "challenge_completed": challenge_completed,
                "confidence": combined_score["overall_score"],
            }

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            if success:
                self.stats["challenges_completed"] += 1
            else:
                self.stats["challenges_failed"] += 1

            processing_time = asyncio.get_event_loop().time() - start_time

            logger.info(
                f"Challenge {challenge_id} verified: success={success}, "
                f"type={session.challenge_type}, time={processing_time:.2f}s"
            )

            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            response = ActiveLivenessVerifyResponse(
                success=success,
                liveness_detected=liveness_detected,
                challenge_completed=challenge_completed,
                confidence=combined_score["overall_score"],
                passive_liveness_score=passive_result["liveness_score"],
                anti_spoofing_score=passive_result["anti_spoofing_score"],
                video_quality=video_quality,
                processing_time_seconds=processing_time,
                frames_analyzed=len(frames),
                failure_reasons=challenge_result.get("failure_reasons", []),
                warnings=challenge_result.get("warnings", []),
            )

            # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if session.challenge_type == "blink":
                response.blink_result = challenge_result.get("blink_result")
            elif session.challenge_type in [
                "turn_head_left",
                "turn_head_right",
                "turn_head_up",
                "turn_head_down",
            ]:
                response.head_movement_result = challenge_result.get(
                    "head_movement_result"
                )

            response.occlusion_result = occlusion_result

            return response

        except Exception as e:
            session.status = "failed"
            logger.error(f"Challenge verification failed: {str(e)}")
            raise

    # ========================================================================
    # Specific Challenge Verification
    # ========================================================================

    async def _verify_specific_challenge(
        self,
        challenge_type: ChallengeType,
        parameters: Dict[str, Any],
        frames: List[np.ndarray],
        landmarks_sequence: List[np.ndarray],
    ) -> Dict[str, Any]:
        """–í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ–≥–æ —Ç–∏–ø–∞ —á–µ–ª–ª–µ–Ω–¥–∂–∞."""

        if challenge_type == "blink":
            return await self._verify_blink_challenge(parameters, landmarks_sequence)

        elif challenge_type == "smile":
            return await self._verify_smile_challenge(parameters, landmarks_sequence)

        elif challenge_type in [
            "turn_head_left",
            "turn_head_right",
            "turn_head_up",
            "turn_head_down",
        ]:
            return await self._verify_head_movement_challenge(
                challenge_type,
                parameters,
                landmarks_sequence,
            )

        elif challenge_type == "open_mouth":
            return await self._verify_mouth_open_challenge(
                parameters, landmarks_sequence
            )

        else:
            raise ValidationError(f"Unknown challenge type: {challenge_type}")

    async def _verify_blink_challenge(
        self,
        parameters: Dict[str, Any],
        landmarks_sequence: List[np.ndarray],
    ) -> Dict[str, Any]:
        """–í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –º–æ—Ä–≥–∞–Ω–∏—è."""

        min_blinks = parameters.get("min_blinks", 2)
        fps = 30.0  # Assumed FPS

        success, blink_count, stats = await asyncio.to_thread(
            detect_blinks_in_sequence,
            landmarks_sequence,
            fps=fps,
            min_blinks=min_blinks,
        )

        blink_result = BlinkDetectionResult(
            blinks_detected=blink_count,
            blinks_required=min_blinks,
            success=success,
            confidence=min(1.0, blink_count / min_blinks),
            average_ear=stats.get("avg_ear", 0.0),
            blink_frames=stats.get("blink_frames", []),
            total_frames_analyzed=stats.get("total_frames", 0),
            quality_issues=[],
        )

        failure_reasons = []
        if not success:
            if blink_count == 0:
                failure_reasons.append("no_blinks_detected")
            else:
                failure_reasons.append(
                    f"insufficient_blinks: {blink_count}/{min_blinks}"
                )

        return {
            "success": success,
            "blink_result": blink_result,
            "failure_reasons": failure_reasons,
            "warnings": [],
        }

    async def _verify_head_movement_challenge(
        self,
        challenge_type: ChallengeType,
        parameters: Dict[str, Any],
        landmarks_sequence: List[np.ndarray],
    ) -> Dict[str, Any]:
        """–í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ–≤–æ—Ä–æ—Ç–∞ –≥–æ–ª–æ–≤—ã."""

        min_angle = parameters.get("min_angle", 15.0)
        direction = parameters.get("direction", "left")

        # –í—ã—á–∏—Å–ª—è–µ–º Euler angles –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–∞–¥—Ä–∞
        euler_angles = []
        for landmarks in landmarks_sequence:
            angles = await asyncio.to_thread(self._calculate_euler_angles, landmarks)
            euler_angles.append(angles)

        # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —É–≥–æ–ª –ø–æ–≤–æ—Ä–æ—Ç–∞ –≤ –Ω—É–∂–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏
        if direction == "left":
            yaw_angles = [angles["yaw"] for angles in euler_angles]
            max_angle = max(yaw_angles)
            detected = max_angle > min_angle
        elif direction == "right":
            yaw_angles = [angles["yaw"] for angles in euler_angles]
            max_angle = abs(min(yaw_angles))
            detected = max_angle > min_angle
        elif direction == "up":
            pitch_angles = [angles["pitch"] for angles in euler_angles]
            max_angle = max(pitch_angles)
            detected = max_angle > min_angle
        elif direction == "down":
            pitch_angles = [angles["pitch"] for angles in euler_angles]
            max_angle = abs(min(pitch_angles))
            detected = max_angle > min_angle
        else:
            detected = False
            max_angle = 0.0

        head_movement_result = HeadMovementResult(
            movement_detected=detected,
            movement_type=direction,
            angle_degrees=max_angle,
            required_angle=min_angle,
            confidence=min(1.0, max_angle / min_angle) if detected else 0.5,
            yaw=euler_angles[-1]["yaw"],
            pitch=euler_angles[-1]["pitch"],
            roll=euler_angles[-1]["roll"],
            frames_analyzed=len(landmarks_sequence),
        )

        failure_reasons = []
        if not detected:
            failure_reasons.append(
                f"insufficient_head_movement: {max_angle:.1f}¬∞/{min_angle:.1f}¬∞"
            )

        return {
            "success": detected,
            "head_movement_result": head_movement_result,
            "failure_reasons": failure_reasons,
            "warnings": [],
        }

    async def _verify_smile_challenge(
        self,
        parameters: Dict[str, Any],
        landmarks_sequence: List[np.ndarray],
    ) -> Dict[str, Any]:
        """–í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è —É–ª—ã–±–∫–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º mouth_detector."""

        intensity_threshold = parameters.get("intensity_threshold", 0.6)
        min_duration_frames = parameters.get("min_duration_frames", 15)

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º detect_smile_in_sequence –∏–∑ mouth_detector
        success, smile_intensity, stats = await asyncio.to_thread(
            detect_smile_in_sequence,
            landmarks_sequence,
            min_intensity=intensity_threshold,
            min_frames_with_smile=min_duration_frames,
        )

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ stats
        smile_frames = stats.get("smile_frames", [])
        max_mar = stats.get("max_mar", 0.0)
        avg_mar = stats.get("avg_mar", 0.0)

        smile_result = SmileDetectionResult(
            smile_detected=success,
            confidence=smile_intensity if success else 0.5,
            mouth_aspect_ratio=avg_mar,
            smile_intensity=smile_intensity,
            frames_with_smile=smile_frames,
            total_frames=stats.get("total_frames", len(landmarks_sequence)),
        )

        failure_reasons = []
        if not success:
            if len(smile_frames) == 0:
                failure_reasons.append("no_smile_detected")
            else:
                failure_reasons.append(
                    f"smile_too_short: {len(smile_frames)}/{min_duration_frames} frames"
                )

        return {
            "success": success,
            "smile_result": smile_result,
            "failure_reasons": failure_reasons,
            "warnings": [],
        }

    async def _verify_mouth_open_challenge(
        self,
        parameters: Dict[str, Any],
        landmarks_sequence: List[np.ndarray],
    ) -> Dict[str, Any]:
        """–í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –æ—Ç–∫—Ä—ã—Ç–æ–≥–æ —Ä—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º mouth_detector."""

        mar_threshold = parameters.get("mouth_aspect_ratio_threshold", 0.5)
        min_duration_frames = parameters.get("min_duration_frames", 10)

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º detect_open_mouth_in_sequence –∏–∑ mouth_detector
        success, max_mar, stats = await asyncio.to_thread(
            detect_open_mouth_in_sequence,
            landmarks_sequence,
            min_mar=mar_threshold,
            min_frames_with_open_mouth=min_duration_frames,
        )

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ stats
        open_frames = stats.get("open_frames", [])
        avg_mar = stats.get("avg_mar", 0.0)

        failure_reasons = []
        if not success:
            if len(open_frames) == 0:
                failure_reasons.append("mouth_not_opened")
            else:
                failure_reasons.append(
                    f"mouth_open_too_short: {len(open_frames)}/{min_duration_frames} frames"
                )

        return {
            "success": success,
            "mouth_open_result": {
                "detected": success,
                "mar": max_mar,
                "avg_mar": avg_mar,
                "frames_with_open_mouth": open_frames,
                "total_frames": stats.get("total_frames", len(landmarks_sequence)),
            },
            "failure_reasons": failure_reasons,
            "warnings": [],
        }

    # ========================================================================
    # Helper Methods
    # ========================================================================

    async def _load_image_sequence(
        self, image_sequence: List[bytes]
    ) -> List[np.ndarray]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π."""
        import io

        from PIL import Image

        frames = []
        for img_data in image_sequence:
            img = Image.open(io.BytesIO(img_data)).convert("RGB")
            frame = np.array(img)
            frames.append(frame)

        return frames

    async def _extract_landmarks_sequence(
        self,
        frames: List[np.ndarray],
    ) -> List[np.ndarray]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ landmarks –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–∞–¥—Ä–∞."""

        landmarks_sequence = []

        for frame in frames:
            landmarks = await asyncio.to_thread(detect_face_landmarks, frame)
            if landmarks is not None:
                landmarks_sequence.append(landmarks)

        return landmarks_sequence

    async def _check_occlusions(
        self,
        frame: np.ndarray,
        landmarks: np.ndarray,
    ) -> OcclusionDetectionResult:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫–∫–ª—é–∑–∏–π."""

        detector = get_occlusion_detector()
        result = await asyncio.to_thread(detector.detect_occlusions, frame, landmarks)

        return OcclusionDetectionResult(
            has_mask=result.has_mask,
            has_sunglasses=result.has_sunglasses,
            has_regular_glasses=result.has_regular_glasses,
            has_vr_headset=result.has_vr_headset,
            has_hand_covering=result.has_hand_covering,
            occlusion_score=result.occlusion_score,
            confidence=result.confidence,
            details=result.details,
        )

    async def _run_passive_liveness(self, frame: np.ndarray) -> Dict[str, float]:
        """–ü–∞—Å—Å–∏–≤–Ω–∞—è liveness –ø—Ä–æ–≤–µ—Ä–∫–∞ (–¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏)."""

        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º ML service
        from .ml_service import get_ml_service

        ml_service = await get_ml_service()

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º frame –≤ bytes
        import io

        from PIL import Image

        pil_image = Image.fromarray(frame)
        img_byte_arr = io.BytesIO()
        pil_image.save(img_byte_arr, format="JPEG")
        img_bytes = img_byte_arr.getvalue()

        # –ó–∞–ø—É—Å–∫–∞–µ–º liveness check
        result = await ml_service.check_liveness(img_bytes, use_3d_depth=True)

        return {
            "liveness_score": result.get("confidence", 0.5),
            "anti_spoofing_score": result.get("anti_spoofing_score", 0.5),
        }

    def _calculate_combined_score(
        self,
        challenge_result: Dict[str, Any],
        passive_result: Dict[str, float],
        occlusion_result: OcclusionDetectionResult,
    ) -> Dict[str, float]:
        """–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∂–∏–≤–æ—Å—Ç–∏."""

        # –í–µ—Å–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        weights = {
            "challenge": 0.5,  # Active challenge
            "passive": 0.3,  # Passive liveness
            "anti_spoofing": 0.15,  # Anti-spoofing
            "occlusion": 0.05,  # Occlusion check
        }

        # –û—Ü–µ–Ω–∫–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        challenge_score = 1.0 if challenge_result["success"] else 0.3
        passive_score = passive_result["liveness_score"]
        anti_spoofing_score = passive_result["anti_spoofing_score"]
        occlusion_score = occlusion_result.occlusion_score

        # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞
        overall_score = (
            challenge_score * weights["challenge"]
            + passive_score * weights["passive"]
            + anti_spoofing_score * weights["anti_spoofing"]
            + occlusion_score * weights["occlusion"]
        )

        return {
            "overall_score": overall_score,
            "challenge_score": challenge_score,
            "passive_score": passive_score,
            "anti_spoofing_score": anti_spoofing_score,
            "occlusion_score": occlusion_score,
        }

    def _calculate_euler_angles(self, landmarks: np.ndarray) -> Dict[str, float]:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ Euler angles –∏–∑ landmarks."""

        # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ —á–µ—Ä–µ–∑ PnP
        # –ú–æ–¥–µ–ª—å–Ω—ã–µ 3D –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫ –ª–∏—Ü–∞
        model_points = np.array(
            [
                (0.0, 0.0, 0.0),  # Nose tip
                (0.0, -330.0, -65.0),  # Chin
                (-225.0, 170.0, -135.0),  # Left eye left corner
                (225.0, 170.0, -135.0),  # Right eye right corner
                (-150.0, -150.0, -125.0),  # Left Mouth corner
                (150.0, -150.0, -125.0),  # Right mouth corner
            ]
        )

        # –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∏–Ω–¥–µ–∫—Å—ã –≤ 68-point landmarks
        image_points = np.array(
            [
                landmarks[30],  # Nose tip
                landmarks[8],  # Chin
                landmarks[36],  # Left eye left corner
                landmarks[45],  # Right eye right corner
                landmarks[48],  # Left mouth corner
                landmarks[54],  # Right mouth corner
            ],
            dtype="double",
        )

        # Camera internals (assumed)
        focal_length = 1.0
        center = (0.0, 0.0)
        camera_matrix = np.array(
            [[focal_length, 0, center[0]], [0, focal_length, center[1]], [0, 0, 1]],
            dtype="double",
        )

        dist_coeffs = np.zeros((4, 1))

        # Solve PnP
        import cv2

        success, rotation_vector, translation_vector = cv2.solvePnP(
            model_points,
            image_points,
            camera_matrix,
            dist_coeffs,
            flags=cv2.SOLVEPNP_ITERATIVE,
        )

        if not success:
            return {"yaw": 0.0, "pitch": 0.0, "roll": 0.0}

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ Euler angles
        rotation_matrix, _ = cv2.Rodrigues(rotation_vector)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —É–≥–ª—ã
        sy = np.sqrt(rotation_matrix[0, 0] ** 2 + rotation_matrix[1, 0] ** 2)
        singular = sy < 1e-6

        if not singular:
            yaw = np.arctan2(rotation_matrix[1, 0], rotation_matrix[0, 0])
            pitch = np.arctan2(-rotation_matrix[2, 0], sy)
            roll = np.arctan2(rotation_matrix[2, 1], rotation_matrix[2, 2])
        else:
            yaw = np.arctan2(-rotation_matrix[1, 2], rotation_matrix[1, 1])
            pitch = np.arctan2(-rotation_matrix[2, 0], sy)
            roll = 0

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –≥—Ä–∞–¥—É—Å—ã
        return {
            "yaw": np.degrees(yaw),
            "pitch": np.degrees(pitch),
            "roll": np.degrees(roll),
        }

    def _count_consecutive_frames(self, frame_indices: List[int]) -> int:
        """–ü–æ–¥—Å—á–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫–∞–¥—Ä–æ–≤."""

        if not frame_indices:
            return 0

        frame_indices = sorted(frame_indices)
        max_consecutive = 1
        current_consecutive = 1

        for i in range(1, len(frame_indices)):
            if frame_indices[i] == frame_indices[i - 1] + 1:
                current_consecutive += 1
                max_consecutive = max(max_consecutive, current_consecutive)
            else:
                current_consecutive = 1

        return max_consecutive

    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–µ—Ä–≤–∏—Å–∞."""
        return {
            **self.stats,
            "active_challenges": len(self._active_challenges),
            "success_rate": (
                self.stats["challenges_completed"]
                / max(
                    1,
                    self.stats["challenges_completed"]
                    + self.stats["challenges_failed"],
                )
            ),
        }

    # ========================================================================
    # Active Liveness Check (—É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
    # ========================================================================

    async def active_liveness_check(
        self,
        video_frames: List[bytes],
        instructions: List[str],
        require_liveness: bool = True,
    ) -> Dict[str, Any]:
        """
        –ê–∫—Ç–∏–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∂–∏–≤–æ—Å—Ç–∏ —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π.

        Args:
            video_frames: –°–ø–∏—Å–æ–∫ –∫–∞–¥—Ä–æ–≤ –≤–∏–¥–µ–æ (bytes JPEG)
            instructions: –°–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
                ["turn_left", "turn_right", "smile", "blink", "open_mouth", "look_up", "look_down"]
            require_liveness: –¢—Ä–µ–±–æ–≤–∞—Ç—å –ø–∞—Å—Å–∏–≤–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –∂–∏–≤–æ—Å—Ç–∏

        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏:
            - passed: bool - –≤—Å–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã + –≤—Å–µ –∫–∞–¥—Ä—ã –∂–∏–≤—ã–µ
            - results: —Å–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ –∫–∞–∂–¥–æ–º—É –∫–∞–¥—Ä—É/–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
            - overall_score: float - –æ–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ (0-1)
            - failed_instructions: —Å–ø–∏—Å–æ–∫ –Ω–µ–≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π
        """
        start_time = asyncio.get_event_loop().time()

        if not video_frames or not instructions:
            raise ValidationError("video_frames and instructions must not be empty")

        if len(video_frames) < len(instructions):
            raise ValidationError(
                f"Got {len(video_frames)} frames for {len(instructions)} instructions"
            )

        logger.info(
            f"Starting active liveness check: {len(instructions)} instructions, "
            f"{len(video_frames)} frames"
        )

        try:
            # 1. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è frames –≤ numpy arrays
            frames_np = await self._frames_bytes_to_numpy(video_frames)

            # 2. –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –≤–∏–¥–µ–æ
            video_quality = self._assess_video_quality(frames_np)
            if video_quality["quality_score"] < 0.4:
                logger.warning(f"Video quality too low: {video_quality}")

            # 3. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ landmarks –¥–ª—è –≤—Å–µ—Ö –∫–∞–¥—Ä–æ–≤
            all_landmarks = await self._extract_all_landmarks(frames_np)

            if len(all_landmarks) < len(video_frames) * 0.7:
                raise ProcessingError(
                    f"Face not detected in enough frames: {len(all_landmarks)}/{len(video_frames)}"
                )

            # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫–∫–ª—é–∑–∏–π –Ω–∞ –ø–µ—Ä–≤–æ–º –∫–∞–¥—Ä–µ
            occlusion_result = await self._check_occlusions(
                frames_np[0], all_landmarks[0] if all_landmarks else None
            )

            # 5. –ü–∞—Å—Å–∏–≤–Ω–∞—è liveness –ø—Ä–æ–≤–µ—Ä–∫–∞
            passive_result = None
            if require_liveness:
                passive_result = await self._run_passive_liveness(frames_np[0])

            # 6. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
            instruction_results = []

            for idx, instruction in enumerate(instructions):
                # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –∫–∞–¥—Ä (–∏–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π –µ—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç)
                frame_idx = min(idx, len(frames_np) - 1)
                frame_landmarks = (
                    all_landmarks[frame_idx] if frame_idx < len(all_landmarks) else None
                )

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
                action_result = await self._detect_action(
                    instruction, frames_np[frame_idx], frame_landmarks
                )

                # –ü–∞—Å—Å–∏–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∂–∏–≤–æ—Å—Ç–∏ –¥–ª—è —ç—Ç–æ–≥–æ –∫–∞–¥—Ä–∞
                liveness_result = None
                if require_liveness:
                    liveness_result = await self._run_passive_liveness(
                        frames_np[frame_idx]
                    )

                instruction_results.append(
                    {
                        "instruction": instruction,
                        "instruction_index": idx,
                        "action_detected": action_result["detected"],
                        "action_confidence": action_result.get("confidence", 0.0),
                        "action_details": action_result.get("details", {}),
                        "liveness": liveness_result,
                    }
                )

            # 7. –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
            action_scores = [r["action_confidence"] for r in instruction_results]
            avg_action_score = np.mean(action_scores) if action_scores else 0.0

            liveness_scores = [
                r["liveness"]["liveness_score"] if r["liveness"] else 0.5
                for r in instruction_results
                if r["liveness"]
            ]
            avg_liveness_score = np.mean(liveness_scores) if liveness_scores else 0.5

            # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
            overall_score = (
                avg_action_score * 0.5
                + avg_liveness_score * 0.3
                + (1 - occlusion_result.occlusion_score) * 0.2
            )

            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å–ø–µ—Ö–∞
            all_actions_passed = all(r["action_detected"] for r in instruction_results)
            all_liveness_passed = all(
                r["liveness"]["liveness_detected"] if r["liveness"] else True
                for r in instruction_results
            )

            passed = all_actions_passed and (
                not require_liveness or all_liveness_passed
            )

            # –°–ø–∏—Å–æ–∫ –Ω–µ—É–¥–∞—á–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π
            failed_instructions = [
                r["instruction"]
                for r in instruction_results
                if not r["action_detected"]
            ]

            processing_time = asyncio.get_event_loop().time() - start_time

            return {
                "passed": passed,
                "overall_score": round(overall_score, 4),
                "action_score": round(avg_action_score, 4),
                "liveness_score": round(avg_liveness_score, 4),
                "instructions_passed": len(instructions) - len(failed_instructions),
                "instructions_total": len(instructions),
                "failed_instructions": failed_instructions,
                "results": instruction_results,
                "occlusion_check": {
                    "occlusion_detected": occlusion_result.occlusion_score > 0.5,
                    "occlusion_score": occlusion_result.occlusion_score,
                },
                "video_quality": video_quality,
                "processing_time": round(processing_time, 4),
                "model_type": "ActiveLiveness",
            }

        except Exception as e:
            logger.error(f"Active liveness check failed: {str(e)}")
            raise ProcessingError(f"Active liveness check failed: {str(e)}")

    async def _detect_action(
        self,
        instruction: str,
        frame: np.ndarray,
        landmarks: Optional[np.ndarray],
    ) -> Dict[str, Any]:
        """
        –î–µ—Ç–µ–∫—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏.

        Args:
            instruction: –¢–∏–ø –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
            frame: –ö–∞–¥—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            landmarks: landmarks –ª–∏—Ü–∞

        Returns:
            Dict —Å detected, confidence, details
        """
        instruction = instruction.lower()

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è landmarks
        if landmarks is None:
            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å landmarks
            landmarks = await asyncio.to_thread(detect_face_landmarks, frame)
            if landmarks is None:
                return {
                    "detected": False,
                    "confidence": 0.0,
                    "error": "No face detected",
                }

        # –î–µ—Ç–µ–∫—Ü–∏—è –ø–æ —Ç–∏–ø—É –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
        if "blink" in instruction or "–≥–ª–∞–∑" in instruction:
            return await self._detect_blink_action(landmarks)

        elif "smile" in instruction or "—É–ª—ã–±" in instruction:
            return await self._detect_smile_action(landmarks)

        elif (
            "turn_left" in instruction
            or "–ø–æ–≤–µ—Ä–Ω–∏—Ç–µ_–≤–ª–µ–≤–æ" in instruction
            or "left" in instruction
        ):
            return await self._detect_head_turn_action(landmarks, "left")

        elif (
            "turn_right" in instruction
            or "–ø–æ–≤–µ—Ä–Ω–∏—Ç–µ_–≤–ø—Ä–∞–≤–æ" in instruction
            or "right" in instruction
        ):
            return await self._detect_head_turn_action(landmarks, "right")

        elif "look_up" in instruction or "–≤–≤–µ—Ä—Ö" in instruction or "up" in instruction:
            return await self._detect_head_turn_action(landmarks, "up")

        elif (
            "look_down" in instruction or "–≤–Ω–∏–∑" in instruction or "down" in instruction
        ):
            return await self._detect_head_turn_action(landmarks, "down")

        elif (
            "open_mouth" in instruction
            or "—Ä–æ—Ç" in instruction
            or "mouth" in instruction
        ):
            return await self._detect_mouth_open_action(landmarks)

        else:
            return {
                "detected": False,
                "confidence": 0.0,
                "error": f"Unknown instruction: {instruction}",
            }

    async def _detect_blink_action(self, landmarks: np.ndarray) -> Dict[str, Any]:
        """–î–µ—Ç–µ–∫—Ü–∏—è –º–æ—Ä–≥–∞–Ω–∏—è –Ω–∞ –æ–¥–Ω–æ–º –∫–∞–¥—Ä–µ."""
        # EAR (Eye Aspect Ratio)
        left_eye = landmarks[42:48]
        right_eye = landmarks[36:42]

        def calc_ear(eye):
            # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
            v1 = np.linalg.norm(eye[1] - eye[5])
            v2 = np.linalg.norm(eye[2] - eye[4])
            # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
            h = np.linalg.norm(eye[0] - eye[3])
            return (v1 + v2) / (2 * h + 1e-6)

        left_ear = calc_ear(left_eye)
        right_ear = calc_ear(right_eye)
        avg_ear = (left_ear + right_ear) / 2

        # –ü–æ—Ä–æ–≥ –¥–ª—è –º–æ—Ä–≥–∞–Ω–∏—è (–æ–±—ã—á–Ω–æ < 0.21)
        is_blinking = avg_ear < self.blink_ear_threshold

        return {
            "detected": is_blinking,
            "confidence": 1.0 - min(avg_ear / 0.21, 1.0),
            "details": {
                "eye_aspect_ratio": round(avg_ear, 4),
                "threshold": self.blink_ear_threshold,
            },
        }

    async def _detect_smile_action(self, landmarks: np.ndarray) -> Dict[str, Any]:
        """–î–µ—Ç–µ–∫—Ü–∏—è —É–ª—ã–±–∫–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º mouth_detector."""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º calculate_mouth_aspect_ratio –∏–∑ mouth_detector
        mar = calculate_mouth_aspect_ratio(landmarks)

        # –£–ª—ã–±–∫–∞ –ø—Ä–∏ MAR > 0.25
        is_smile = mar > 0.25

        return {
            "detected": is_smile,
            "confidence": min(mar / 0.5, 1.0),
            "details": {
                "mouth_aspect_ratio": round(mar, 4),
                "threshold": 0.25,
            },
        }

    async def _detect_head_turn_action(
        self,
        landmarks: np.ndarray,
        direction: str,
    ) -> Dict[str, Any]:
        """–î–µ—Ç–µ–∫—Ü–∏—è –ø–æ–≤–æ—Ä–æ—Ç–∞ –≥–æ–ª–æ–≤—ã."""
        # –í—ã—á–∏—Å–ª—è–µ–º yaw –∏–∑ landmarks
        nose = landmarks[30]
        left_eye = np.mean(landmarks[36:42], axis=0)
        right_eye = np.mean(landmarks[42:48], axis=0)

        # Yaw angle
        eye_center = (left_eye + right_eye) / 2
        nose_offset = nose[0] - eye_center[0]

        # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–π —É–≥–æ–ª –ø–æ–≤–æ—Ä–æ—Ç–∞
        yaw = np.degrees(np.arctan2(nose_offset, eye_center[0] - nose[0]))

        if direction == "left":
            detected = yaw > self.head_movement_min_angle
            angle = yaw
        elif direction == "right":
            detected = yaw < -self.head_movement_min_angle
            angle = abs(yaw)
        elif direction == "up":
            # Pitch –≤–≤–µ—Ä—Ö - –Ω–æ—Å –≤—ã—à–µ —Ü–µ–Ω—Ç—Ä–∞ –º–µ–∂–¥—É –≥–ª–∞–∑–∞–º–∏
            nose_y = nose[1]
            eye_center_y = eye_center[1]
            detected = nose_y < eye_center_y - 10
            angle = abs(eye_center_y - nose_y)
        elif direction == "down":
            detected = nose_y > eye_center_y + 10
            angle = abs(nose_y - eye_center_y)
        else:
            detected = False
            angle = 0.0

        return {
            "detected": detected,
            "confidence": min(angle / 30.0, 1.0),
            "details": {
                "direction": direction,
                "angle_degrees": round(angle, 2),
                "required_angle": self.head_movement_min_angle,
            },
        }

    async def _detect_mouth_open_action(self, landmarks: np.ndarray) -> Dict[str, Any]:
        """–î–µ—Ç–µ–∫—Ü–∏—è –æ—Ç–∫—Ä—ã—Ç–æ–≥–æ —Ä—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º mouth_detector."""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º calculate_mouth_aspect_ratio –∏–∑ mouth_detector
        mar = calculate_mouth_aspect_ratio(landmarks)

        is_open = mar > 0.5

        return {
            "detected": is_open,
            "confidence": min(mar / 0.7, 1.0),
            "details": {
                "mouth_aspect_ratio": round(mar, 4),
                "threshold": 0.5,
            },
        }

    async def _frames_bytes_to_numpy(self, frames: List[bytes]) -> List[np.ndarray]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è bytes –≤ numpy arrays."""
        import io

        from PIL import Image

        result = []
        for frame_bytes in frames:
            img = Image.open(io.BytesIO(frame_bytes)).convert("RGB")
            result.append(np.array(img))

        return result

    async def _extract_all_landmarks(
        self,
        frames: List[np.ndarray],
    ) -> List[np.ndarray]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ landmarks –¥–ª—è –≤—Å–µ—Ö –∫–∞–¥—Ä–æ–≤."""
        landmarks_list = []

        for frame in frames:
            landmarks = await asyncio.to_thread(detect_face_landmarks, frame)
            if landmarks is not None:
                landmarks_list.append(landmarks)

        return landmarks_list

    def _assess_video_quality(self, frames: List[np.ndarray]) -> Dict[str, Any]:
        """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –≤–∏–¥–µ–æ."""
        if not frames:
            return {"quality_score": 0.0, "blur_score": 0.0, "brightness_score": 0.0}

        # –û—Ü–µ–Ω–∫–∞ –Ω–∞ –ø–µ—Ä–≤–æ–º –∫–∞–¥—Ä–µ (–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ)
        frame = frames[0]
        gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)

        # –†–µ–∑–∫–æ—Å—Ç—å
        laplacian = cv2.Laplacian(gray, cv2.CV_64F)
        blur_score = np.std(laplacian) / 500.0

        # –Ø—Ä–∫–æ—Å—Ç—å
        brightness = np.mean(gray) / 255.0

        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        quality_score = min(blur_score, 1.0) * 0.5 + abs(brightness - 0.5) * 2 * 0.5

        return {
            "quality_score": round(min(quality_score, 1.0), 4),
            "blur_score": round(min(blur_score, 1.0), 4),
            "brightness_score": round(brightness, 4),
        }


# Singleton
_active_liveness_service: Optional[ActiveLivenessService] = None


async def get_active_liveness_service() -> ActiveLivenessService:
    """Get or create singleton service."""
    global _active_liveness_service
    if _active_liveness_service is None:
        _active_liveness_service = ActiveLivenessService()
    return _active_liveness_service
