"""
API —Ä–æ—É—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∂–∏–≤–æ—Å—Ç–∏ (Liveness Detection).

Endpoints:
- POST /liveness/check - –ü–∞—Å—Å–∏–≤–Ω–∞—è liveness (–æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)
- POST /liveness/video - –ü–∞—Å—Å–∏–≤–Ω–∞—è liveness (–≤–∏–¥–µ–æ)
- POST /liveness/active/challenge - –°–æ–∑–¥–∞–Ω–∏–µ Active Liveness —á–µ–ª–ª–µ–Ω–¥–∂–∞
- POST /liveness/active/verify - –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è Active Liveness —á–µ–ª–ª–µ–Ω–¥–∂–∞
- POST /liveness/blink - –°–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –º–æ—Ä–≥–∞–Ω–∏—è
- POST /liveness/head-movement - –î–µ—Ç–µ–∫—Ü–∏—è –¥–≤–∏–∂–µ–Ω–∏—è –≥–æ–ª–æ–≤—ã
- GET /liveness/active/stats - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ Active Liveness
"""

from fastapi import APIRouter, Depends, UploadFile, File, Form, HTTPException, Body
from typing import Optional, List
import base64

from ..models.response import BaseResponse
from ..models.request import LivenessRequest, VideoLivenessRequest
from ..models.active_liveness import (
    ActiveLivenessChallengeRequest,
    ActiveLivenessVerifyRequest,
    ActiveLivenessChallengeResponse,
    ActiveLivenessVerifyResponse,
    BlinkDetectionRequest,
    HeadMovementRequest,
    ChallengeType,
)
from ..services.ml_service import get_ml_service
from ..services.active_liveness_service import get_active_liveness_service
from ..dependencies import get_current_user
from ..utils.logger import get_logger
from ..utils.exceptions import ValidationError, ProcessingError

router = APIRouter(prefix="/liveness", tags=["liveness"])
logger = get_logger(__name__)


# ============================================================================
# PASSIVE LIVENESS (—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ endpoints)
# ============================================================================

@router.post("/check", response_model=BaseResponse)
async def check_liveness(
    file: UploadFile = File(..., description="–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∂–∏–≤–æ—Å—Ç–∏"),
    challenge_type: str = Form(default="passive", description="–¢–∏–ø —á–µ–ª–ª–µ–Ω–¥–∂–∞"),
    user: dict = Depends(get_current_user),
):
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ –∂–∏–≤–æ—Å—Ç–∏ –ø–æ –æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é (–ø–∞—Å—Å–∏–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞).
    
    Features:
    - MiniFASNetV2 anti-spoofing (>98% accuracy)
    - 3D depth analysis
    - Lighting/shadow analysis
    - Texture analysis
    
    **–ú–µ—Ç–æ–¥—ã:**
    - Certified: MiniFASNetV2 (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
    - Heuristic: 3D depth + lighting (fallback)
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
        if not file.content_type.startswith("image/"):
            raise ValidationError(f"Invalid file type: {file.content_type}. Expected image.")
        
        # –ß–∏—Ç–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image_data = await file.read()
        
        if len(image_data) > 10 * 1024 * 1024:  # 10MB limit
            raise ValidationError("Image size exceeds 10MB limit")
        
        # –ü–æ–ª—É—á–∞–µ–º ML —Å–µ—Ä–≤–∏—Å
        ml_service = await get_ml_service()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∂–∏–≤–æ—Å—Ç–∏
        result = await ml_service.check_liveness(
            image_data=image_data,
            challenge_type=challenge_type,
            use_3d_depth=True,
        )
        
        logger.info(
            f"Liveness check: user={user['user_id']}, "
            f"detected={result.get('liveness_detected')}, "
            f"confidence={result.get('confidence'):.3f}"
        )
        
        return BaseResponse(
            success=True,
            message="Liveness check completed",
            data=result,
        )
        
    except ValidationError as e:
        logger.warning(f"Liveness validation error: {str(e)}")
        raise HTTPException(status_code=400, detail=str(e))
    except ProcessingError as e:
        logger.error(f"Liveness processing error: {str(e)}")
        raise HTTPException(status_code=422, detail=str(e))
    except Exception as e:
        logger.error(f"Liveness check failed: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail="Internal server error")


@router.post("/video", response_model=BaseResponse)
async def check_video_liveness(
    file: UploadFile = File(..., description="–í–∏–¥–µ–æ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∂–∏–≤–æ—Å—Ç–∏ (MP4, WebM)"),
    challenge_type: str = Form(default="passive", description="–¢–∏–ø —á–µ–ª–ª–µ–Ω–¥–∂–∞"),
    max_frames: int = Form(default=30, description="–ú–∞–∫—Å–∏–º—É–º –∫–∞–¥—Ä–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"),
    user: dict = Depends(get_current_user),
):
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ –∂–∏–≤–æ—Å—Ç–∏ –ø–æ –≤–∏–¥–µ–æ (–ø–∞—Å—Å–∏–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞).
    
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–∞–¥—Ä–æ–≤ –≤–∏–¥–µ–æ –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–π –¥–µ—Ç–µ–∫—Ü–∏–∏.
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
        if not file.content_type.startswith("video/"):
            raise ValidationError(f"Invalid file type: {file.content_type}. Expected video.")
        
        # –ß–∏—Ç–∞–µ–º –≤–∏–¥–µ–æ
        video_data = await file.read()
        
        if len(video_data) > 50 * 1024 * 1024:  # 50MB limit
            raise ValidationError("Video size exceeds 50MB limit")
        
        # –ü–æ–ª—É—á–∞–µ–º ML —Å–µ—Ä–≤–∏—Å
        ml_service = await get_ml_service()
        
        # –ê–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ (–ø–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π –∫–∞–¥—Ä, TODO: –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑)
        from ..utils.video_processing import extract_frames_from_video
        
        frames = await extract_frames_from_video(
            video_data,
            max_frames=max_frames,
            target_fps=10,
        )
        
        if not frames:
            raise ProcessingError("No frames could be extracted from video")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–π –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π –∫–∞–¥—Ä
        from PIL import Image
        import io
        
        first_frame = Image.fromarray(frames[0])
        img_byte_arr = io.BytesIO()
        first_frame.save(img_byte_arr, format='JPEG')
        first_frame_bytes = img_byte_arr.getvalue()
        
        result = await ml_service.check_liveness(
            image_data=first_frame_bytes,
            challenge_type=challenge_type,
            use_3d_depth=True,
        )
        
        result["frames_analyzed"] = len(frames)
        result["video_duration_frames"] = len(frames)
        
        logger.info(
            f"Video liveness check: user={user['user_id']}, "
            f"frames={len(frames)}, "
            f"detected={result.get('liveness_detected')}"
        )
        
        return BaseResponse(
            success=True,
            message="Video liveness check completed",
            data=result,
        )
        
    except ValidationError as e:
        logger.warning(f"Video liveness validation error: {str(e)}")
        raise HTTPException(status_code=400, detail=str(e))
    except ProcessingError as e:
        logger.error(f"Video liveness processing error: {str(e)}")
        raise HTTPException(status_code=422, detail=str(e))
    except Exception as e:
        logger.error(f"Video liveness check failed: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail="Internal server error")


# ============================================================================
# ACTIVE LIVENESS (–Ω–æ–≤—ã–µ endpoints)
# ============================================================================

@router.post("/active/challenge", response_model=ActiveLivenessChallengeResponse)
async def create_active_liveness_challenge(
    request: ActiveLivenessChallengeRequest,
    user: dict = Depends(get_current_user),
):
    """
    –°–æ–∑–¥–∞–Ω–∏–µ Active Liveness —á–µ–ª–ª–µ–Ω–¥–∂–∞.
    
    **Challenge Types:**
    - `blink` - –ú–æ—Ä–≥–∞–Ω–∏–µ (2-3 —Ä–∞–∑–∞)
    - `smile` - –£–ª—ã–±–∫–∞
    - `turn_head_left` - –ü–æ–≤–æ—Ä–æ—Ç –≥–æ–ª–æ–≤—ã –≤–ª–µ–≤–æ
    - `turn_head_right` - –ü–æ–≤–æ—Ä–æ—Ç –≥–æ–ª–æ–≤—ã –≤–ø—Ä–∞–≤–æ
    - `turn_head_up` - –ù–∞–∫–ª–æ–Ω –≥–æ–ª–æ–≤—ã –≤–≤–µ—Ä—Ö
    - `turn_head_down` - –ù–∞–∫–ª–æ–Ω –≥–æ–ª–æ–≤—ã –≤–Ω–∏–∑
    - `open_mouth` - –û—Ç–∫—Ä—ã—Ç—å —Ä–æ—Ç
    - `random` - –°–ª—É—á–∞–π–Ω—ã–π —á–µ–ª–ª–µ–Ω–¥–∂ (–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è —Å–µ—Ä–≤–µ—Ä–æ–º)
    
    **Difficulty:**
    - `easy` - –õ–µ–≥–∫–æ (–º–µ–Ω—å—à–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π)
    - `medium` - –°—Ä–µ–¥–Ω–µ (—Å—Ç–∞–Ω–¥–∞—Ä—Ç)
    - `hard` - –°–ª–æ–∂–Ω–æ (—Å—Ç—Ä–æ–≥–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è)
    
    **Response —Å–æ–¥–µ—Ä–∂–∏—Ç:**
    - `challenge_id` - ID –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏
    - `instruction` - –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    - `expires_at` - –í—Ä–µ–º—è –∏—Å—Ç–µ—á–µ–Ω–∏—è —á–µ–ª–ª–µ–Ω–¥–∂–∞
    
    **–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:**
    1. –°–æ–∑–¥–∞–π—Ç–µ —á–µ–ª–ª–µ–Ω–¥–∂ (–ø–æ–ª—É—á–∏—Ç–µ `challenge_id`)
    2. –ü–æ–∫–∞–∂–∏—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é
    3. –ó–∞–ø–∏—à–∏—Ç–µ –≤–∏–¥–µ–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    4. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –Ω–∞ `/active/verify` —Å `challenge_id`
    """
    try:
        service = await get_active_liveness_service()
        
        response = await service.create_challenge(
            challenge_type=request.challenge_type,
            timeout_seconds=request.timeout_seconds,
            difficulty=request.difficulty,
        )
        
        logger.info(
            f"Challenge created: user={user['user_id']}, "
            f"type={request.challenge_type}, "
            f"id={response.challenge_id}"
        )
        
        return response
        
    except Exception as e:
        logger.error(f"Failed to create challenge: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail="Failed to create challenge")


@router.post("/active/verify", response_model=ActiveLivenessVerifyResponse)
async def verify_active_liveness_challenge(
    challenge_id: str = Form(..., description="ID —á–µ–ª–ª–µ–Ω–¥–∂–∞"),
    file: Optional[UploadFile] = File(None, description="–í–∏–¥–µ–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —á–µ–ª–ª–µ–Ω–¥–∂–∞"),
    metadata: Optional[str] = Form(None, description="–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ JSON"),
    user: dict = Depends(get_current_user),
):
    """
    –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è Active Liveness —á–µ–ª–ª–µ–Ω–¥–∂–∞.
    
    **–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
    - –í–∏–¥–µ–æ –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —á–µ–ª–ª–µ–Ω–¥–∂–∞
    - –ú–∏–Ω–∏–º—É–º 20 –∫–∞–¥—Ä–æ–≤ (0.5-1 —Å–µ–∫—É–Ω–¥–∞ –ø—Ä–∏ 30 FPS)
    - –ö–∞—á–µ—Å—Ç–≤–æ: —Ä–µ–∑–∫–æ—Å—Ç—å, –æ—Å–≤–µ—â–µ–Ω–∏–µ, –≤–∏–¥–∏–º–æ—Å—Ç—å –ª–∏—Ü–∞
    - –õ–∏—Ü–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤–∏–¥–Ω–æ –Ω–∞ –≤—Å–µ—Ö –∫–∞–¥—Ä–∞—Ö
    
    **–ü—Ä–æ–≤–µ—Ä–∫–∏:**
    1. **Active Challenge** - –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è
    2. **Passive Liveness** - MiniFASNetV2 anti-spoofing
    3. **Occlusion Detection** - –º–∞—Å–∫–∏, –æ—á–∫–∏, —Ä—É–∫–∏
    4. **Video Quality** - —Ä–µ–∑–∫–æ—Å—Ç—å, –æ—Å–≤–µ—â–µ–Ω–∏–µ, —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
    
    **Response:**
    - `liveness_detected` - –æ–±—â–∞—è –∂–∏–≤–æ—Å—Ç—å
    - `challenge_completed` - –≤—ã–ø–æ–ª–Ω–µ–Ω –ª–∏ —á–µ–ª–ª–µ–Ω–¥–∂
    - `confidence` - —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (0-1)
    - –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–∞–∂–¥–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
    """
    try:
        if not file:
            raise ValidationError("Video file is required")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
        if not file.content_type.startswith("video/"):
            raise ValidationError(f"Invalid file type: {file.content_type}. Expected video.")
        
        # –ß–∏—Ç–∞–µ–º –≤–∏–¥–µ–æ
        video_data = await file.read()
        
        if len(video_data) > 100 * 1024 * 1024:  # 100MB limit
            raise ValidationError("Video size exceeds 100MB limit")
        
        # –ü–∞—Ä—Å–∏–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        import json
        metadata_dict = None
        if metadata:
            try:
                metadata_dict = json.loads(metadata)
            except json.JSONDecodeError:
                logger.warning(f"Failed to parse metadata: {metadata}")
        
        # –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è
        service = await get_active_liveness_service()
        
        response = await service.verify_challenge(
            challenge_id=challenge_id,
            video_data=video_data,
            metadata=metadata_dict,
        )
        
        logger.info(
            f"Challenge verified: user={user['user_id']}, "
            f"id={challenge_id}, "
            f"success={response.success}, "
            f"confidence={response.confidence:.3f}"
        )
        
        return response
        
    except ValidationError as e:
        logger.warning(f"Challenge verification validation error: {str(e)}")
        raise HTTPException(status_code=400, detail=str(e))
    except ProcessingError as e:
        logger.error(f"Challenge verification processing error: {str(e)}")
        raise HTTPException(status_code=422, detail=str(e))
    except Exception as e:
        logger.error(f"Challenge verification failed: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail="Internal server error")


@router.post("/blink", response_model=BaseResponse)
async def detect_blink(
    file: UploadFile = File(..., description="–í–∏–¥–µ–æ —Å –º–æ—Ä–≥–∞–Ω–∏–µ–º"),
    min_blinks: int = Form(default=1, ge=1, le=5, description="–ú–∏–Ω–∏–º—É–º –º–æ—Ä–≥–∞–Ω–∏–π"),
    user: dict = Depends(get_current_user),
):
    """
    –î–µ—Ç–µ–∫—Ü–∏—è –º–æ—Ä–≥–∞–Ω–∏—è –≤ –≤–∏–¥–µ–æ (–±–µ–∑ —Å–æ–∑–¥–∞–Ω–∏—è —á–µ–ª–ª–µ–Ω–¥–∂–∞).
    
    **–ü—Ä—è–º–æ–π –º–µ—Ç–æ–¥** –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–æ—Ä–≥–∞–Ω–∏—è –±–µ–∑ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è —á–µ–ª–ª–µ–Ω–¥–∂–∞.
    
    **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**
    - `min_blinks` - –¢—Ä–µ–±—É–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ—Ä–≥–∞–Ω–∏–π (1-5)
    
    **–ê–ª–≥–æ—Ä–∏—Ç–º:**
    - Eye Aspect Ratio (EAR) –ø–æ –º–µ—Ç–æ–¥—É Soukupov√° & ƒåech
    - –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å: –≥–ª–∞–∑ –æ—Ç–∫—Ä—ã—Ç ‚Üí –∑–∞–∫—Ä—ã—Ç ‚Üí –æ—Ç–∫—Ä—ã—Ç
    - –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (100-400ms)
    
    **Response:**
    - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ—Ä–≥–∞–Ω–∏–π
    - –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–µ—Ç–µ–∫—Ü–∏–∏
    - –ù–æ–º–µ—Ä–∞ –∫–∞–¥—Ä–æ–≤ —Å –º–æ—Ä–≥–∞–Ω–∏—è–º–∏
    """
    try:
        # –ß–∏—Ç–∞–µ–º –≤–∏–¥–µ–æ
        video_data = await file.read()
        
        if len(video_data) > 50 * 1024 * 1024:
            raise ValidationError("Video size exceeds 50MB limit")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–¥—Ä—ã
        from ..utils.video_processing import extract_frames_from_video
        
        frames = extract_frames_from_video(video_data, max_frames=300, target_fps=30)
        
        if len(frames) < 10:
            raise ProcessingError("Insufficient frames in video")
        
        # –î–µ—Ç–µ–∫—Ü–∏—è landmarks
        from ..utils.face_alignment_utils import detect_face_landmarks
        
        landmarks_sequence = []
        for frame in frames:
            landmarks = detect_face_landmarks(frame)
            if landmarks is not None:
                landmarks_sequence.append(landmarks)
        
        if len(landmarks_sequence) < 10:
            raise ProcessingError("Face not detected in enough frames")
        
        # –î–µ—Ç–µ–∫—Ü–∏—è –º–æ—Ä–≥–∞–Ω–∏–π
        from ..utils.eye_blink_detector import detect_blinks_in_sequence
        
        success, blink_count, stats = detect_blinks_in_sequence(
            landmarks_sequence,
            fps=30.0,
            min_blinks=min_blinks,
        )
        
        result = {
            "blinks_detected": blink_count,
            "blinks_required": min_blinks,
            "success": success,
            "confidence": min(1.0, blink_count / min_blinks),
            "blink_frames": stats.get("blink_frames", []),
            "total_frames": len(landmarks_sequence),
            "average_ear": stats.get("avg_ear", 0.0),
        }
        
        logger.info(
            f"Blink detection: user={user['user_id']}, "
            f"blinks={blink_count}/{min_blinks}, "
            f"success={success}"
        )
        
        return BaseResponse(
            success=True,
            message="Blink detection completed",
            data=result,
        )
        
    except ValidationError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except ProcessingError as e:
        raise HTTPException(status_code=422, detail=str(e))
    except Exception as e:
        logger.error(f"Blink detection failed: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail="Internal server error")


@router.post("/head-movement", response_model=BaseResponse)
async def detect_head_movement(
    file: UploadFile = File(..., description="–í–∏–¥–µ–æ —Å –¥–≤–∏–∂–µ–Ω–∏–µ–º –≥–æ–ª–æ–≤—ã"),
    movement_type: str = Form(..., description="–¢–∏–ø –¥–≤–∏–∂–µ–Ω–∏—è: left/right/up/down"),
    min_angle: float = Form(default=15.0, description="–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —É–≥–æ–ª (–≥—Ä–∞–¥—É—Å—ã)"),
    user: dict = Depends(get_current_user),
):
    """
    –î–µ—Ç–µ–∫—Ü–∏—è –¥–≤–∏–∂–µ–Ω–∏—è –≥–æ–ª–æ–≤—ã –≤ –≤–∏–¥–µ–æ.
    
    **–¢–∏–ø—ã –¥–≤–∏–∂–µ–Ω–∏–π:**
    - `left` - –ü–æ–≤–æ—Ä–æ—Ç –≤–ª–µ–≤–æ (yaw > 0)
    - `right` - –ü–æ–≤–æ—Ä–æ—Ç –≤–ø—Ä–∞–≤–æ (yaw < 0)
    - `up` - –ù–∞–∫–ª–æ–Ω –≤–≤–µ—Ä—Ö (pitch > 0)
    - `down` - –ù–∞–∫–ª–æ–Ω –≤–Ω–∏–∑ (pitch < 0)
    
    **–ê–ª–≥–æ—Ä–∏—Ç–º:**
    - PnP pose estimation —Å 6 –∫–ª—é—á–µ–≤—ã–º–∏ —Ç–æ—á–∫–∞–º–∏
    - –í—ã—á–∏—Å–ª–µ–Ω–∏–µ Euler angles (yaw, pitch, roll)
    - –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —É–≥–ª–∞ –≤ –Ω—É–∂–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏
    
    **Response:**
    - –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏ –¥–≤–∏–∂–µ–Ω–∏–µ
    - –£–≥–æ–ª –ø–æ–≤–æ—Ä–æ—Ç–∞ (–≥—Ä–∞–¥—É—Å—ã)
    - Euler angles (yaw, pitch, roll)
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–∞ –¥–≤–∏–∂–µ–Ω–∏—è
        valid_movements = ["left", "right", "up", "down"]
        if movement_type not in valid_movements:
            raise ValidationError(f"Invalid movement_type. Must be one of: {valid_movements}")
        
        # –ß–∏—Ç–∞–µ–º –≤–∏–¥–µ–æ
        video_data = await file.read()
        
        if len(video_data) > 50 * 1024 * 1024:
            raise ValidationError("Video size exceeds 50MB limit")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–¥—Ä—ã
        from ..utils.video_processing import extract_frames_from_video
        
        frames = extract_frames_from_video(video_data, max_frames=300, target_fps=30)
        
        if len(frames) < 10:
            raise ProcessingError("Insufficient frames in video")
        
        # –î–µ—Ç–µ–∫—Ü–∏—è landmarks
        from ..utils.face_alignment_utils import detect_face_landmarks
        
        landmarks_sequence = []
        for frame in frames:
            landmarks = detect_face_landmarks(frame)
            if landmarks is not None:
                landmarks_sequence.append(landmarks)
        
        if len(landmarks_sequence) < 10:
            raise ProcessingError("Face not detected in enough frames")
        
        # –í—ã—á–∏—Å–ª—è–µ–º —É–≥–ª—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–∞–¥—Ä–∞
        service = await get_active_liveness_service()
        
        euler_angles = []
        for landmarks in landmarks_sequence:
            angles = service._calculate_euler_angles(landmarks)
            euler_angles.append(angles)
        
        # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —É–≥–æ–ª
        if movement_type == "left":
            yaw_angles = [angles["yaw"] for angles in euler_angles]
            max_angle = max(yaw_angles)
            detected = max_angle > min_angle
        elif movement_type == "right":
            yaw_angles = [angles["yaw"] for angles in euler_angles]
            max_angle = abs(min(yaw_angles))
            detected = max_angle > min_angle
        elif movement_type == "up":
            pitch_angles = [angles["pitch"] for angles in euler_angles]
            max_angle = max(pitch_angles)
            detected = max_angle > min_angle
        else:  # down
            pitch_angles = [angles["pitch"] for angles in euler_angles]
            max_angle = abs(min(pitch_angles))
            detected = max_angle > min_angle
        
        result = {
            "movement_detected": detected,
            "movement_type": movement_type,
            "angle_degrees": max_angle,
            "required_angle": min_angle,
            "confidence": min(1.0, max_angle / min_angle) if detected else 0.5,
            "euler_angles": euler_angles[-1] if euler_angles else {},
            "frames_analyzed": len(landmarks_sequence),
        }
        
        logger.info(
            f"Head movement detection: user={user['user_id']}, "
            f"type={movement_type}, "
            f"angle={max_angle:.1f}¬∞, "
            f"detected={detected}"
        )
        
        return BaseResponse(
            success=True,
            message="Head movement detection completed",
            data=result,
        )
        
    except ValidationError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except ProcessingError as e:
        raise HTTPException(status_code=422, detail=str(e))
    except Exception as e:
        logger.error(f"Head movement detection failed: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail="Internal server error")


@router.get("/active/stats", response_model=BaseResponse)
async def get_active_liveness_stats(
    user: dict = Depends(get_current_user),
):
    """
    –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ Active Liveness —Å–µ—Ä–≤–∏—Å–∞.
    
    **–ú–µ—Ç—Ä–∏–∫–∏:**
    - –í—Å–µ–≥–æ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö —á–µ–ª–ª–µ–Ω–¥–∂–µ–π
    - –£—Å–ø–µ—à–Ω—ã—Ö/–ø—Ä–æ–≤–∞–ª—å–Ω—ã—Ö –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–π
    - Success rate
    - –ê–∫—Ç–∏–≤–Ω—ã–µ —á–µ–ª–ª–µ–Ω–¥–∂–∏
    
    **–î–æ—Å—Ç—É–ø:** —Ç–æ–ª—å–∫–æ –¥–ª—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
    """
    try:
        service = await get_active_liveness_service()
        stats = service.get_stats()
        
        return BaseResponse(
            success=True,
            message="Active liveness statistics",
            data=stats,
        )
        
    except Exception as e:
        logger.error(f"Failed to get stats: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail="Failed to get statistics")


# ============================================================================
# UTILITY ENDPOINTS
# ============================================================================

@router.get("/supported-challenges", response_model=BaseResponse)
async def get_supported_challenges():
    """
    –°–ø–∏—Å–æ–∫ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ç–∏–ø–æ–≤ —á–µ–ª–ª–µ–Ω–¥–∂–µ–π.
    
    **–ü—É–±–ª–∏—á–Ω—ã–π endpoint** - –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏.
    """
    challenges = [
        {
            "type": "blink",
            "name": "–ú–æ—Ä–≥–∞–Ω–∏–µ",
            "description": "–ú–æ—Ä–≥–Ω–∏—Ç–µ 2-3 —Ä–∞–∑–∞",
            "difficulty": ["easy", "medium", "hard"],
            "icon": "üëÅÔ∏è",
        },
        {
            "type": "smile",
            "name": "–£–ª—ã–±–∫–∞",
            "description": "–£–ª—ã–±–Ω–∏—Ç–µ—Å—å",
            "difficulty": ["easy", "medium", "hard"],
            "icon": "üòä",
        },
        {
            "type": "turn_head_left",
            "name": "–ü–æ–≤–æ—Ä–æ—Ç –≤–ª–µ–≤–æ",
            "description": "–ü–æ–≤–µ—Ä–Ω–∏—Ç–µ –≥–æ–ª–æ–≤—É –≤–ª–µ–≤–æ",
            "difficulty": ["easy", "medium", "hard"],
            "icon": "‚¨ÖÔ∏è",
        },
        {
            "type": "turn_head_right",
            "name": "–ü–æ–≤–æ—Ä–æ—Ç –≤–ø—Ä–∞–≤–æ",
            "description": "–ü–æ–≤–µ—Ä–Ω–∏—Ç–µ –≥–æ–ª–æ–≤—É –≤–ø—Ä–∞–≤–æ",
            "difficulty": ["easy", "medium", "hard"],
            "icon": "‚û°Ô∏è",
        },
        {
            "type": "turn_head_up",
            "name": "–ù–∞–∫–ª–æ–Ω –≤–≤–µ—Ä—Ö",
            "description": "–ù–∞–∫–ª–æ–Ω–∏—Ç–µ –≥–æ–ª–æ–≤—É –≤–≤–µ—Ä—Ö",
            "difficulty": ["easy", "medium", "hard"],
            "icon": "‚¨ÜÔ∏è",
        },
        {
            "type": "turn_head_down",
            "name": "–ù–∞–∫–ª–æ–Ω –≤–Ω–∏–∑",
            "description": "–ù–∞–∫–ª–æ–Ω–∏—Ç–µ –≥–æ–ª–æ–≤—É –≤–Ω–∏–∑",
            "difficulty": ["easy", "medium", "hard"],
            "icon": "‚¨áÔ∏è",
        },
        {
            "type": "open_mouth",
            "name": "–û—Ç–∫—Ä—ã—Ç—å —Ä–æ—Ç",
            "description": "–û—Ç–∫—Ä–æ–π—Ç–µ —Ä–æ—Ç",
            "difficulty": ["easy", "medium", "hard"],
            "icon": "üòÆ",
        },
        {
            "type": "random",
            "name": "–°–ª—É—á–∞–π–Ω—ã–π",
            "description": "–°–µ—Ä–≤–µ—Ä –≤—ã–±–µ—Ä–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π —á–µ–ª–ª–µ–Ω–¥–∂",
            "difficulty": ["medium"],
            "icon": "üé≤",
        },
    ]
    
    return BaseResponse(
        success=True,
        message="Supported challenge types",
        data={
            "challenges": challenges,
            "total": len(challenges),
        },
    )

